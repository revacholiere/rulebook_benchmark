Driving Agents
===
In this directory, we interface existing driving policies with our benchmark for evaluation on the scenarios.

Interface to a Policy
---
This section describes how to interface a driving policy with a Scenic program.

### 1. Define a Policy Agent
Create a class that inherits the `Agent` class defined in `agent.py`. The class must implement a `run_step` method, which generates the control actions (e.g., throttle, brake, steer) for the next timestep.
```python
class ExampleAgent(Agent):
    def run_step(self, *args, **kwargs):
        ...
        throttle, brake, steer = ... # Generated by the driving policy
        return throttle, brake, steer
```

### 2. Define a Scenic Car
Create a class that inherits from Scenic’s Car class. In the `startDynamicSimulation` method, assign an instance of your policy agent (`ExampleAgent`) to `self.controller`.
```scenic
class ExampleCar(Car):
    controller: None

    def startDynamicSimulation(self):
        self.controller = ExampleAgent()
```

### 3. Define an Action
Create a class that inherits from the `AgentAction` class (defined in `agent.py`). This class must implement an `applyTo` method, where the first argument agent is an `ExampleCar` instance. Inside `applyTo`, call `agent.controller.run_step` to retrieve control actions, then use Scenic’s built-in methods (`setThrottle`, `setBraking`, `setSteering`, etc.) to apply them.
```python
class ExampleAction(AgentAction):
    def applyTo(self, agent, *args, **kwargs):
        ...
        throttle, brake, steer = agent.controller.run_step(...)
        agent.setThrottle(throttle)
        agent.setBraking(brake)
        agent.setSteering(steer)
```

### 4. Define a Behavior
Create a Scenic behavior that repeatedly takes the `ExampleAction`.
The `take` specifier calls the `applyTo` method defined in the action.
```scenic
behavior ExampleBehavior():
    action = ExampleAction()
    take action
    while True:
        take action
```

### 5. Assign the Ego Car
In the Scenic program, define the ego car as an `ExampleCar` with the `ExampleBehavior`. The ego car will now be controlled by the given policy.
```scenic
ego = new ExampleCar at ...,
    with ...,
    with behavior ExampleBehavior()
```

### 6. Passing State Information to the Policy
Most, if not all, policies require access to the ego’s current state or environment state. To pass this information from Scenic to `run_step`, follow these steps:

#### 6a. Create a Global Variable and Monitor
At each timestep, the monitor stores the current state into a global variable.
```scenic
SPEED = []

monitor UpdateState():
while True:
    SPEED.append(ego.speed)
    wait
```
> Note: The global variable is a list, and the most recent value is the last element (`SPEED[-1]`). This is due to Scenic’s internal handling of variables.
    
#### 6b. Require the Monitor
Ensure the monitor is active throughout the simulation:
```scenic
require monitor UpdateState()
```

#### 6c. Store State in the Car Class
Add a member variable in `ExampleCar` to store the current state, updating it each timestep:
```scenic
class ExampleCar(Car):
    speed: None
    controller: None

    def update_actor(self):
        self.speed = SPEED[-1]

    def startDynamicSimulation(self):
        self.controller = ExampleAgent()
```

#### 6d. Pass State to the Policy
Update `ExampleAction.applyTo` to pass the current state to `run_step`.
Optionally, you can pass the entire Scenic agent (`ExampleCar`) if needed.
```python
class ExampleAction(AgentAction):
    def applyTo(self, agent, *args, **kwargs):
        ...
        throttle, brake, steer = agent.controller.run_step(agent.speed, agent, ...)
        agent.setThrottle(throttle)
        agent.setBraking(brake)
        agent.setSteering(steer)
```

Interface to the MetaDrive Expert PPO Agent
---
Related files: `metadrive_expert_agent.py`, `metadrive_expert.scenic`

The MetaDrive simulator provides a PPO expert policy ([metadrive.examples.ppo_expert.numpy_expert](https://github.com/metadriverse/metadrive/blob/main/metadrive/examples/ppo_expert/numpy_expert.py)). It's a three-layer MLP with an input dimension of 275 and an output dimension of 2. The input space consists of the ego states (dim = 9), the navigation info (dim = 10), other vehicles' information (dim = 16), and Lidar observations (dim = 240). The outputs are steer and throttle_brake.

In the `MetaDrivePolicyAgent` class, we replicate the expert policy by converting Scenic information to the inputs of the neural network. The details of the conversion are as follows:
* Ego states
    * lateral_to_left: The distance from ego to the opposite lane, divided by the total road width. If the opposite lane is None, set to 0.5.
    * lateral_to_right: The distance from ego to the right curb, divided by the total road width.
    * angular_diff: The angle between the ego's heading and the lane's heading. Use tanh to normalize angle to [0, 1], with more weight on small angle. If the lane heading is to the right (resp. left) of ego heading, the value is close to 1 (resp. 0).
    * curr_speed: Directly use the information from MetaDrive.
    * curr_steering: Directly use the information from MetaDrive.
    * throttle/brake of last frame: Directly use the information from MetaDrive.
    * steering of last frame: Directly use the information from MetaDrive.
    * yaw_rate: Directly use the information from MetaDrive.
    * lateral_offset: The distance to the centerline of the current lane. The value is 0.5 if the ego is on the centerline. The value is negative (resp. positive) if the ego is to the right (resp. left) of the centerline.

* Navigation information: The Metadrive expert requires the information of the "current checkpoint" and the "next checkpoint". We assume the planned trajectory of the ego vehicle is provided in Scenic, where the planned trajectory consists of several lanes. Then, the current checkpoint information is based on the current lane, and the next checkpoint information is based on the next lane in the trajectory. We use the ego's position to update the current and the next lane.

* Other vehicles' information: Directly use the information from MetaDrive.

* Lidar observations: Directly use the information from MetaDrive.
